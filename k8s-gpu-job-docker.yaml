apiVersion: v1
kind: Pod
metadata:
  name: pytorch-gpu-pod
spec:
  restartPolicy: Never
  containers:
  - name: pytorch-container
    image: pytorch/pytorch:latest
    command: ["sleep", "infinity"]
    resources:
      limits:
        nvidia.com/gpu: 1
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: "all"
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: "compute,utility"
    volumeMounts:
    # GPU Device Files
    - name: nvidia0
      mountPath: /dev/nvidia0
    - name: nvidiactl
      mountPath: /dev/nvidiactl
    - name: nvidia-uvm
      mountPath: /dev/nvidia-uvm
    - name: nvidia-uvm-tools
      mountPath: /dev/nvidia-uvm-tools
    - name: nvidia-modeset
      mountPath: /dev/nvidia-modeset
    # NVIDIA Binaries
    - name: nvidia-smi
      mountPath: /usr/bin/nvidia-smi
    # NVIDIA Libraries
    - name: libcuda-so-1
      mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so.1
    - name: libnvidia-ml-so-1
      mountPath: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1
  volumes:
  # GPU Device Files
  - name: nvidia0
    hostPath:
      path: /dev/nvidia0
  - name: nvidiactl
    hostPath:
      path: /dev/nvidiactl
  - name: nvidia-uvm
    hostPath:
      path: /dev/nvidia-uvm
  - name: nvidia-uvm-tools
    hostPath:
      path: /dev/nvidia-uvm-tools
  - name: nvidia-modeset
    hostPath:
      path: /dev/nvidia-modeset
  # NVIDIA Binaries
  - name: nvidia-smi
    hostPath:
      path: /usr/bin/nvidia-smi
  # NVIDIA Libraries
  - name: libcuda-so-1
    hostPath:
      path: /usr/lib/x86_64-linux-gnu/libcuda.so.1
  - name: libnvidia-ml-so-1
    hostPath:
      path: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1
  nodeSelector:
    accelerator: nvidia 